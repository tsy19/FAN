{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import TwolayerNet, MLP, AbstainNet\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import load_data\n",
    "\n",
    "import os\n",
    "import time\n",
    "from options import args_parser\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class namespace:\n",
    "    def __init__(self):\n",
    "        self.batch_size=128\n",
    "        self.device='cuda:1'\n",
    "        self.epoch=30000\n",
    "        self.hidden_dim=300\n",
    "        self.input_dim=108\n",
    "        self.load_from_disk=True\n",
    "        self.lr=0.0005\n",
    "        self.seed=1\n",
    "        self.fairness_notion=\"DP\"\n",
    "        self.attribute=\"sex\"\n",
    "        self.type_of_abstain=\"prob\"\n",
    "\n",
    "args = namespace()\n",
    "args.model_path = \"../data/OptimalClassifier\"\n",
    "args.data_path = \"../data/adult\"\n",
    "\n",
    "train_data, test_data = load_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_optimal(args):\n",
    "    model = MLP(args)\n",
    "\n",
    "    checkpoint = torch.load(os.path.join(args.model_path, \"model_state.pth\"), map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    model.to(\"cpu\")\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "def load_abstain(args):\n",
    "    model = AbstainNet(args)\n",
    "    \n",
    "    model_file = os.path.join(\"../data/AbstainClassifier\", \"abstain_classifier_\" + \\\n",
    "                            args.type_of_abstain+\"_\" + \\\n",
    "                            args.fairness_notion + \"_\" + \\\n",
    "                            args.attribute + \".pth\")\n",
    "    \n",
    "    checkpoint = torch.load(model_file, map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.to(\"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_abstain(model, data, pred_labels):\n",
    "    X = data.X.numpy()\n",
    "    X = np.column_stack((X, pred_labels))\n",
    "    log_probs = model(torch.from_numpy(X).to(torch.float))\n",
    "    return log_probs.detach().cpu().numpy().flatten()\n",
    "\n",
    "def predict(model, data):\n",
    "    log_probs = model(data.X)\n",
    "    return ((log_probs[:, 1] >= 0.5) * 1).detach().cpu().numpy(), log_probs[:, 1].detach().cpu().numpy()\n",
    "\n",
    "def formatted(numbers):\n",
    "    return [f\"{num*100:.2f}%\" for num in numbers]\n",
    "def plot_stats(\n",
    "    y,\n",
    "    pred_labels,\n",
    "    g1_indices, \n",
    "    g2_indices,\n",
    "    wprob,\n",
    "    wbi\n",
    "):\n",
    "    n = pred_labels.shape[0]\n",
    "    g1_num = g1_indices.shape[0]\n",
    "    g2_num = g2_indices.shape[0]\n",
    "    total_error = pred_labels != y\n",
    "    g1_error = (pred_labels != y)[g1_indices]\n",
    "    g2_error = (pred_labels != y)[g2_indices]\n",
    "    \n",
    "    g1_error_rate = np.sum(g1_error) / g1_num\n",
    "    g2_error_rate = np.sum(g2_error) / g2_num\n",
    "    total_error_rate = np.sum(total_error) / n\n",
    "    \n",
    "\n",
    "    g1_prob_error_rate = np.sum(wprob[g1_indices] * g1_error) / np.sum(wprob[g1_indices])\n",
    "    g2_prob_error_rate = np.sum(wprob[g2_indices] * g2_error) / np.sum(wprob[g2_indices])\n",
    "    total_prob_error_rate = np.sum(wprob * total_error) / np.sum(wprob)\n",
    "\n",
    "    g1_bi_error_rate = np.sum(wbi[g1_indices] * g1_error) / np.sum(wbi[g1_indices])\n",
    "    g2_bi_error_rate = np.sum(wbi[g2_indices] * g2_error) / np.sum(wbi[g2_indices])\n",
    "    total_bi_error_rate = np.sum(wbi * total_error) / np.sum(wbi)\n",
    "\n",
    "\n",
    "\n",
    "    optimal_accu = [1 - total_error_rate, 1 - g1_error_rate, 1 - g2_error_rate]\n",
    "    prob_accu = [\n",
    "        1 - total_prob_error_rate,\n",
    "        1 - g1_prob_error_rate,\n",
    "        1 - g2_prob_error_rate\n",
    "    ]\n",
    "    bi_accu = [\n",
    "        1 - total_bi_error_rate,\n",
    "        1 - g1_bi_error_rate,\n",
    "        1 - g2_bi_error_rate\n",
    "    ]\n",
    "\n",
    "    optimal_fairness = [\n",
    "        np.sum(pred_labels) / n, \n",
    "        np.sum(pred_labels[g1_indices]) / g1_num, \n",
    "        np.sum(pred_labels[g2_indices]) / g2_num\n",
    "    ]\n",
    "    prob_fairness = [\n",
    "        np.sum(wprob * pred_labels) / n,\n",
    "        np.sum((wprob * pred_labels)[g1_indices]) / g1_num,\n",
    "        np.sum((wprob * pred_labels)[g2_indices]) / g2_num,\n",
    "    ]\n",
    "    bi_fairness = [\n",
    "        np.sum(wbi * pred_labels) / n,\n",
    "        np.sum((wbi * pred_labels)[g1_indices]) / g1_num,\n",
    "        np.sum((wbi * pred_labels)[g2_indices]) / g2_num,\n",
    "    ]\n",
    "\n",
    "\n",
    "    #Abstain rate\n",
    "    optimal_abstain_rate = [0, 0, 0]\n",
    "    prob_abstain_rate = [\n",
    "        1 - np.sum(wprob) / n, \n",
    "        1 - np.sum(wprob[g1_indices]) / g1_num, \n",
    "        1 - np.sum(wprob[g2_indices]) / g2_num,\n",
    "    ]\n",
    "    bi_abstain_rate = [\n",
    "        1 - np.sum(wbi) / n, \n",
    "        1 - np.sum(wbi[g1_indices]) / g1_num, \n",
    "        1 - np.sum(wbi[g2_indices]) / g2_num,\n",
    "    ]\n",
    "\n",
    "    # plt.bar([\"\", \"b\", \"c\"],[1 - total_error_rate, 1 - g1_error_rate, 1 - g2_error_rate])\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "\n",
    "    #accuracy\n",
    "    bar_width = 0.25\n",
    "    x_labels = [\"Overall\", \"G1\", \"G2\"]\n",
    "    x_pos = np.arange(len(x_labels))\n",
    "    ax[0,0].bar(x_pos - bar_width, optimal_accu, width=bar_width, label='Opt. Clas.')\n",
    "    ax[0,0].bar(x_pos, prob_accu, width=bar_width, label='Prob.')\n",
    "    ax[0,0].bar(x_pos + bar_width, bi_accu, width=bar_width, label='Binary')\n",
    "    ax[0,0].set_ylim([0.85, 1])\n",
    "    ax[0,0].set_ylabel(\"Accuracy\")\n",
    "    ax[0,0].set_title(\"Accuracy\")\n",
    "    ax[0,0].set_xticks(x_pos)\n",
    "    ax[0,0].set_xticklabels(x_labels)\n",
    "    ax[0,0].legend()\n",
    "\n",
    "\n",
    "    #fairness\n",
    "    bar_width = 0.25\n",
    "    x_labels = [\"Overall\", \"G1\", \"G2\"]\n",
    "    x_pos = np.arange(len(x_labels))\n",
    "    ax[0,1].bar(x_pos - bar_width, optimal_fairness, width=bar_width, label='Opt. Clas.')\n",
    "    ax[0,1].bar(x_pos, prob_fairness, width=bar_width, label='Prob.')\n",
    "    ax[0,1].bar(x_pos + bar_width, bi_fairness, width=bar_width, label='Binary')\n",
    "    # ax[0,1].set_ylim([0.85, 1])\n",
    "    ax[0,1].set_ylabel('$P(\\\\hat{y} = 1 | G)$')\n",
    "    ax[0,1].set_title(\"Demographic Parity\")\n",
    "    ax[0,1].set_xticks(x_pos)\n",
    "    ax[0,1].set_xticklabels(x_labels)\n",
    "    ax[0,1].legend()\n",
    "\n",
    "    #proportion\n",
    "    ax[1,0].pie([g1_num, g2_num], labels=['G1', 'G2'], autopct='%1.1f%%', startangle=90)\n",
    "    ax[1,0].set_title('Proportion')\n",
    "\n",
    "    #abstain rate\n",
    "    bar_width = 0.25\n",
    "    x_labels = [\"Overall\", \"G1\", \"G2\"]\n",
    "    x_pos = np.arange(len(x_labels))\n",
    "#     ax[1,1].bar(x_pos - bar_width, optimal_abstain_rate, width=bar_width, label='Opt. Clas.')\n",
    "    ax[1,1].bar(x_pos, prob_abstain_rate, width=bar_width, label='Prob.')\n",
    "    ax[1,1].bar(x_pos + bar_width, bi_abstain_rate, width=bar_width, label='Binary')\n",
    "    # ax[0,1].set_ylim([0.85, 1])\n",
    "    ax[1,1].set_ylabel('Abstain Rate')\n",
    "    ax[1,1].set_title(\"Abstain Rate\")\n",
    "    ax[1,1].set_xticks(x_pos)\n",
    "    ax[1,1].set_xticklabels(x_labels)\n",
    "    ax[1,1].legend()\n",
    "\n",
    "\n",
    "    fig.suptitle(args.attribute + \" as Sensitive Attribute(G1=Male, G2=Female, \"+ '$\\delta=$' + str(delta) + ', $\\epsilon=$' + str(epsilon) +\")\", fontsize=30)\n",
    "\n",
    "    print(\"==Optimal Classifier==\\n\")\n",
    "    print(\"Accuracy\", \" \".join(formatted(optimal_accu)))\n",
    "    print(\"P(\\hat{y} = 1 | G)\", \" \".join(formatted(optimal_fairness)))\n",
    "    print(\"Abstain Rate\", \" \".join(formatted(optimal_abstain_rate)))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"==Abstain with Probability==\\n\")\n",
    "    print(\"Accuracy\", \" \".join(formatted(prob_accu)))\n",
    "    print(\"P(\\hat{y} = 1 | G)\", \" \".join(formatted(prob_fairness)))\n",
    "    print(\"Abstain Rate\", \" \".join(formatted(prob_abstain_rate)))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"==Abstain as Binary==\\n\")\n",
    "    print(\"Accuracy\", \" \".join(formatted(bi_accu)))\n",
    "    print(\"P(\\hat{y} = 1 | G)\", \" \".join(formatted(bi_fairness)))\n",
    "    print(\"Abstain Rate\", \" \".join(formatted(bi_abstain_rate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load optimal classifier and get stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "optimal_classifier = load_optimal(args)\n",
    "pred_labels, pred_probs = predict(optimal_classifier, data)\n",
    "# np.save(\"../data/adult/optimal_labels.npy\", pred_labels)\n",
    "pred_labels_test, _ = predict(optimal_classifier, test_data)\n",
    "# np.save(\"../data/adult/test_optimal_labels.npy\", pred_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.X.numpy()\n",
    "y = data.y.numpy().astype(int)\n",
    "\n",
    "n = X.shape[0]\n",
    "g2_indices = np.where(X[:, 64] == 1)[0]\n",
    "g1_indices = np.where(X[:, 65] == 1)[0]\n",
    "\n",
    "g1_num = g1_indices.shape[0]\n",
    "g2_num = g2_indices.shape[0]\n",
    "total_error = pred_labels != y\n",
    "g1_error = (pred_labels != y)[g1_indices]\n",
    "g2_error = (pred_labels != y)[g2_indices]\n",
    "g1_error_rate = np.sum(g1_error) / g1_num\n",
    "g2_error_rate = np.sum(g2_error) / g2_num\n",
    "total_error_rate = np.sum(total_error) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LP optimazation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP(delta, epsilon, eta, data):\n",
    "    X = data.X.numpy()\n",
    "    y = data.y.numpy().astype(int)\n",
    "\n",
    "    n = X.shape[0]\n",
    "    g2_indices = np.where(X[:, 64] == 1)[0]\n",
    "    g1_indices = np.where(X[:, 65] == 1)[0]\n",
    "\n",
    "    g1_num = g1_indices.shape[0]\n",
    "    g2_num = g2_indices.shape[0]\n",
    "    total_error = pred_labels != y\n",
    "    g1_error = (pred_labels != y)[g1_indices]\n",
    "    g2_error = (pred_labels != y)[g2_indices]\n",
    "    g1_error_rate = np.sum(g1_error) / g1_num\n",
    "    g2_error_rate = np.sum(g2_error) / g2_num\n",
    "    total_error_rate = np.sum(total_error) / n\n",
    "    w = cp.Variable(n)\n",
    "\n",
    "    objective = cp.Minimize(cp.sum(cp.multiply(total_error, w)))\n",
    "\n",
    "    constraints = [\n",
    "        w <= 1,\n",
    "        w >= 0,\n",
    "        (cp.sum(cp.multiply(w, pred_labels)[g1_indices]) / g1_num - cp.sum(cp.multiply(w, pred_labels)[g2_indices]) / g2_num) ** 2 <= epsilon ** 2,\n",
    "        cp.sum(w[g1_indices]) >= (1 - delta) * g1_num,\n",
    "        cp.sum(w[g2_indices]) >= (1 - delta) * g2_num,\n",
    "        cp.sum(cp.multiply(w[g1_indices], g1_error)) <= (g1_error_rate + eta) * cp.sum(w[g1_indices]),\n",
    "        cp.sum(cp.multiply(w[g2_indices], g2_error)) <= (g2_error_rate + eta) * cp.sum(w[g2_indices]),\n",
    "    ]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    result = prob.solve()\n",
    "    \n",
    "    \n",
    "    \n",
    "    wn = w.value\n",
    "    \n",
    "    return wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve and plot, tune hyperparameter here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.2\n",
    "epsilon = 0.1\n",
    "eta = 0\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use wn as abstain result\n",
      "\n",
      "Not feasible!\n"
     ]
    }
   ],
   "source": [
    "print(\"Use wn as abstain result\\n\")\n",
    "X = train_data.X.numpy()\n",
    "y = train_data.y.numpy().astype(int)\n",
    "g2_indices = np.where(X[:, 64] == 1)[0]\n",
    "g1_indices = np.where(X[:, 65] == 1)[0]\n",
    "#draw decision with probability wn\n",
    "wn = LP(delta, epsilon, eta, train_data)\n",
    "if wn is None:\n",
    "    print(\"Not feasible!\")\n",
    "else:\n",
    "    plt.plot(np.sort(wn))\n",
    "    plt.title(\"$w_n$ for each data point\")\n",
    "    plt.xlabel(\"data points\")\n",
    "    plt.ylabel(\"value\")\n",
    "    wprob = (np.random.rand(len(wn)) < wn) * 1\n",
    "    #use wn as binary classifier\n",
    "    wbi = (wn >= threshold) * 1\n",
    "    plot_stats(\n",
    "        y,\n",
    "        pred_labels,\n",
    "        g1_indices, \n",
    "        g2_indices,\n",
    "        wprob,\n",
    "        wbi\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_list = np.arange(0.15, 0.31, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22, 0.23, 0.24, 0.25,\n",
       "       0.26, 0.27, 0.28, 0.29, 0.3 ])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_value = np.arange(20) * 0.005 + 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.16\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.17\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.18000000000000002\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.19000000000000003\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.20000000000000004\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.21000000000000005\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.22000000000000006\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.1\n",
      "0.23000000000000007\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n",
      "0.085\n",
      "0.09000000000000001\n",
      "0.095\n",
      "0.24000000000000007\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.07500000000000001\n",
      "0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyin/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py:1386: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  \"Solution may be inaccurate. Try another solver, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2500000000000001\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.07\n",
      "0.2600000000000001\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.06\n",
      "0.065\n",
      "0.27000000000000013\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.045\n",
      "0.049999999999999996\n",
      "0.055\n",
      "0.28000000000000014\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.04\n",
      "0.29000000000000015\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.030000000000000002\n",
      "0.034999999999999996\n",
      "0.30000000000000016\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "delta_list = np.arange(0.15, 0.31, 0.01)\n",
    "epsilon_value = np.arange(20) * 0.005 + 0.005\n",
    "eta = 0.1\n",
    "threshold = 0.5\n",
    "epsilon_list = []\n",
    "end_index = len(epsilon_value)\n",
    "for delta in delta_list:\n",
    "    print(delta)\n",
    "    eps_value = -1\n",
    "    for i, epsilon in enumerate(epsilon_value[:end_index]):\n",
    "        print(epsilon)\n",
    "        wn = LP(delta, epsilon, eta, train_data)\n",
    "        if wn is None:\n",
    "            continue\n",
    "        else:\n",
    "            eps_value = epsilon\n",
    "            end_index = i + 1\n",
    "            break\n",
    "    epsilon_list.append(eps_value)\n",
    "plt.plot(delta_list, epsilon_list, \"*\")\n",
    "plt.xlabel(\"$\\delta$\")\n",
    "plt.ylabel(\"$\\epsilon$\")\n",
    "plt.title(\"Feasibility Region for LP (Minimum $\\epsilon$ for Each $\\delta$, $\\eta=$ + str(eta))\")\n",
    "# plt.xticks([0.15, 0.20, 0.25, 0.30])\n",
    "plt.ylim([0, 0.11])\n",
    "plt.savefig(\"feasible_eta01.png\", bbox_inches=\"tight\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(epsilon_list)):\n",
    "    if epsilon_list[i] == 0:\n",
    "        epsilon_list[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
